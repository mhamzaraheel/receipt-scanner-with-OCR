{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T04:07:55.339022900Z",
     "start_time": "2023-12-19T04:07:55.298293400Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision import models\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T03:16:58.785274100Z",
     "start_time": "2023-12-19T03:16:58.769651700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define data transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T03:16:59.103831100Z",
     "start_time": "2023-12-19T03:16:59.086427100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define data directory\n",
    "data_dir = r'./Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T03:16:59.511478200Z",
     "start_time": "2023-12-19T03:16:59.421644800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the entire datas\n",
    "data = datasets.ImageFolder(data_dir, transform=data_transforms['train'])\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(data))\n",
    "val_size = len(data) - train_size\n",
    "train_data, val_data = random_split(data, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T03:17:00.053276400Z",
     "start_time": "2023-12-19T03:17:00.024578400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_data_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=4)\n",
    "val_data_loader = DataLoader(val_data, batch_size=128, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T03:23:13.249525800Z",
     "start_time": "2023-12-19T03:22:57.422382700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the first batch\n",
    "train_features_batch, train_labels_batch = next(iter(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T03:23:13.265147Z",
     "start_time": "2023-12-19T03:23:13.249525800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 3, 224, 224]), torch.Size([128]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the first batch\n",
    "train_features_batch.shape,train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T03:23:13.327632900Z",
     "start_time": "2023-12-19T03:23:13.265147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.4314, 0.4157, 0.4392,  ..., 0.1804, 0.1529, 0.1216],\n",
       "          [0.4431, 0.4392, 0.4431,  ..., 0.1294, 0.0902, 0.0745],\n",
       "          [0.4275, 0.4392, 0.4392,  ..., 0.0549, 0.0471, 0.0431],\n",
       "          ...,\n",
       "          [0.0196, 0.0196, 0.0235,  ..., 0.0196, 0.0235, 0.0235],\n",
       "          [0.0196, 0.0196, 0.0196,  ..., 0.0196, 0.0196, 0.0196],\n",
       "          [0.0196, 0.0196, 0.0196,  ..., 0.0196, 0.0196, 0.0196]],\n",
       " \n",
       "         [[0.2784, 0.2588, 0.2745,  ..., 0.1176, 0.0980, 0.0706],\n",
       "          [0.2863, 0.2824, 0.2824,  ..., 0.0784, 0.0471, 0.0392],\n",
       "          [0.2549, 0.2667, 0.2863,  ..., 0.0235, 0.0196, 0.0235],\n",
       "          ...,\n",
       "          [0.0196, 0.0196, 0.0196,  ..., 0.0275, 0.0275, 0.0235],\n",
       "          [0.0196, 0.0196, 0.0196,  ..., 0.0196, 0.0196, 0.0196],\n",
       "          [0.0196, 0.0196, 0.0196,  ..., 0.0196, 0.0196, 0.0196]],\n",
       " \n",
       "         [[0.1647, 0.1569, 0.1843,  ..., 0.1137, 0.0863, 0.0431],\n",
       "          [0.1804, 0.1765, 0.1843,  ..., 0.0824, 0.0431, 0.0235],\n",
       "          [0.1608, 0.1647, 0.1686,  ..., 0.0275, 0.0196, 0.0235],\n",
       "          ...,\n",
       "          [0.0196, 0.0196, 0.0157,  ..., 0.0235, 0.0235, 0.0157],\n",
       "          [0.0196, 0.0196, 0.0196,  ..., 0.0196, 0.0196, 0.0196],\n",
       "          [0.0196, 0.0196, 0.0196,  ..., 0.0196, 0.0196, 0.0196]]]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first image and label from the first batch\n",
    "train_features_batch[0],train_labels_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T03:23:13.327632900Z",
     "start_time": "2023-12-19T03:23:13.296389700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['other_documents', 'receipt']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T03:34:34.322827400Z",
     "start_time": "2023-12-19T03:34:34.291365Z"
    }
   },
   "outputs": [],
   "source": [
    "class DocumentClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=2, pretrained=True):\n",
    "        super(DocumentClassifier, self).__init__()\n",
    "        self.resnet = models.resnet18(pretrained=pretrained)\n",
    "        in_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T03:34:35.863473200Z",
     "start_time": "2023-12-19T03:34:35.846054400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Device agnostic code\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T03:34:36.553418200Z",
     "start_time": "2023-12-19T03:34:36.245008900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the model & define loss function and optimizer\n",
    "model = DocumentClassifier(num_classes=2, pretrained=True).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T04:24:01.022547100Z",
     "start_time": "2023-12-19T04:24:01.006290900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate Accuracy\n",
    "def accuracy_fn(label_true, label_pred):\n",
    "    correct = torch.eq(label_true, label_pred).sum().item()\n",
    "    acc = (correct / len(label_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T03:57:40.698502800Z",
     "start_time": "2023-12-19T03:46:05.308658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673eaf61dd8a476e83db1262ba718991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 0/4352 samples\n",
      "\n",
      "Train loss: 0.26719 | Test loss: 0.20171, Test acc: 92.82%\n",
      "\n",
      "Looked at 0/4352 samples\n",
      "\n",
      "Train loss: 0.10104 | Test loss: 0.34789, Test acc: 85.35%\n",
      "\n",
      "Looked at 0/4352 samples\n",
      "\n",
      "Train loss: 0.09164 | Test loss: 0.09773, Test acc: 96.19%\n",
      "\n",
      "Looked at 0/4352 samples\n",
      "\n",
      "Train loss: 0.07635 | Test loss: 0.46796, Test acc: 89.95%\n",
      "\n",
      "Looked at 0/4352 samples\n",
      "\n",
      "Train loss: 0.07659 | Test loss: 0.09964, Test acc: 96.02%\n",
      "\n",
      "Looked at 0/4352 samples\n",
      "\n",
      "Train loss: 0.07785 | Test loss: 0.09482, Test acc: 97.14%\n",
      "\n",
      "Looked at 0/4352 samples\n",
      "\n",
      "Train loss: 0.05877 | Test loss: 0.09611, Test acc: 95.59%\n",
      "\n",
      "Looked at 0/4352 samples\n",
      "\n",
      "Train loss: 0.06556 | Test loss: 0.10686, Test acc: 95.50%\n",
      "\n",
      "Looked at 0/4352 samples\n",
      "\n",
      "Train loss: 0.05789 | Test loss: 0.36376, Test acc: 88.14%\n",
      "\n",
      "Looked at 0/4352 samples\n",
      "\n",
      "Train loss: 0.08082 | Test loss: 0.17037, Test acc: 95.05%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch, (inputs, labels) in enumerate(train_data_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "         # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        # Calculate loss (per batch)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Cumulatively add up the loss per epoch\n",
    "        train_loss += loss\n",
    "        # Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        # Loss backward\n",
    "        loss.backward()\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print out how many samples have been seen\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(inputs)}/{len(train_data_loader.dataset)} samples\")\n",
    "\n",
    "    # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
    "    train_loss /= len(train_data_loader)\n",
    "\n",
    "    # Testing phase\n",
    "    model.eval()\n",
    "    val_loss, val_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for inputs, labels in val_data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Calculate loss (cumulatively)\n",
    "            val_loss += loss\n",
    "            # 3. Calculate accuracy\n",
    "            val_acc += accuracy_fn(label_true=labels, label_pred=outputs.argmax(dim=1))\n",
    "\n",
    "        # Divide total val loss by length of val dataloader (average loss per batch per epoch)\n",
    "        val_loss /= len(val_data_loader)\n",
    "\n",
    "        # Divide total val accuracy by length of val dataloader (average acc per batch per epoch)\n",
    "        val_acc /= len(val_data_loader)\n",
    "\n",
    "    ## Print out what's happening\n",
    "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {val_loss:.5f}, Test acc: {val_acc:.2f}%\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('Trained_Model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
